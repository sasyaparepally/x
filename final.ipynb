{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjvD9y6EFF40",
        "outputId": "68597f5a-4910-4c31-aae3-7081ebc77af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.6)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, pytorch-tabnet, optuna, catboost\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 catboost-1.2.7 colorlog-6.9.0 optuna-4.1.0 pytorch-tabnet-4.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn catboost xgboost pytorch-tabnet optuna torch tabulate joblib matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import optuna\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "from tabulate import tabulate\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class AdvancedEnsembleModel:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.power_transformer = PowerTransformer(method='yeo-johnson')\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.feature_encoders = {}\n",
        "        self.models = {}\n",
        "        self.best_params = {}\n",
        "        self.feature_importance = {}\n",
        "        self.known_labels = None\n",
        "\n",
        "    def create_advanced_features(self, X):\n",
        "        X = X.copy()\n",
        "        numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        # Reduced number of ratio features (only most important ones)\n",
        "        main_numeric_cols = numeric_cols[:5]  # Take only first 5 numeric columns\n",
        "        for i in range(len(main_numeric_cols)):\n",
        "            for j in range(i + 1, len(main_numeric_cols)):\n",
        "                col1, col2 = main_numeric_cols[i], main_numeric_cols[j]\n",
        "                ratio_name = f'ratio_{col1}_{col2}'\n",
        "                X[ratio_name] = X[col1] / (X[col2] + 1e-6)\n",
        "\n",
        "        # Simplified statistical aggregations\n",
        "        for col in main_numeric_cols:\n",
        "            X[f'{col}_zscore'] = (X[col] - X[col].mean()) / (X[col].std() + 1e-6)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def preprocess_data(self, X, train_mode=True):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Handle missing values\n",
        "        for col in X.columns:\n",
        "            if X[col].dtype in [np.float64, np.float32, np.int64, np.int32]:\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "            else:\n",
        "                X[col] = X[col].fillna('unknown')\n",
        "\n",
        "        # Encode categorical variables\n",
        "        if train_mode:\n",
        "            for col in X.select_dtypes(include=['object']).columns:\n",
        "                self.feature_encoders[col] = LabelEncoder()\n",
        "                # Add 'unknown' to encoder classes if not present\n",
        "                unique_values = list(X[col].unique())\n",
        "                if 'unknown' not in unique_values:\n",
        "                    unique_values.append('unknown')\n",
        "                self.feature_encoders[col].fit(unique_values)\n",
        "                X[col] = self.feature_encoders[col].transform(X[col].astype(str))\n",
        "        else:\n",
        "            for col in self.feature_encoders.keys():\n",
        "                if col in X.columns:\n",
        "                    X[col] = X[col].astype(str)\n",
        "                    # Map unseen categories to 'unknown'\n",
        "                    X[col] = X[col].map(lambda x: 'unknown' if x not in self.feature_encoders[col].classes_ else x)\n",
        "                    X[col] = self.feature_encoders[col].transform(X[col])\n",
        "\n",
        "        # Create advanced features\n",
        "        X = self.create_advanced_features(X)\n",
        "\n",
        "        # Scale numeric features\n",
        "        if train_mode:\n",
        "            X = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns)\n",
        "            X = pd.DataFrame(self.power_transformer.fit_transform(X), columns=X.columns)\n",
        "        else:\n",
        "            X = pd.DataFrame(self.scaler.transform(X), columns=X.columns)\n",
        "            X = pd.DataFrame(self.power_transformer.transform(X), columns=X.columns)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        print(\"Starting advanced model training...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Store known labels and ensure 'unknown' is included\n",
        "        self.known_labels = list(np.unique(y))\n",
        "        if 'unknown' not in self.known_labels:\n",
        "            self.known_labels.append('unknown')\n",
        "\n",
        "        # Preprocess the data\n",
        "        print(\"Preprocessing data...\")\n",
        "        X_processed = self.preprocess_data(X, train_mode=True)\n",
        "        self.label_encoder.fit(self.known_labels)\n",
        "        y_encoded = self.label_encoder.transform(y)\n",
        "\n",
        "        # Train CatBoost with optimized iterations\n",
        "        print(\"Training CatBoost...\")\n",
        "        self.models['catboost'] = CatBoostClassifier(\n",
        "            iterations=30,\n",
        "            learning_rate=0.25,\n",
        "            depth=4,\n",
        "            l2_leaf_reg=3,\n",
        "            bootstrap_type='Bayesian',\n",
        "            verbose=0,\n",
        "            random_seed=42\n",
        "        )\n",
        "        self.models['catboost'].fit(X_processed, y_encoded)\n",
        "\n",
        "        # Train XGBoost with optimized iterations\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['xgboost'] = XGBClassifier(\n",
        "            n_estimators=30,\n",
        "            learning_rate=0.25,\n",
        "            max_depth=4,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42,\n",
        "            tree_method='hist'\n",
        "        )\n",
        "        self.models['xgboost'].fit(X_processed, y_encoded)\n",
        "\n",
        "        # Train TabNet with optimized parameters\n",
        "        print(\"Training TabNet...\")\n",
        "        self.models['tabnet'] = TabNetClassifier(\n",
        "            n_d=8,\n",
        "            n_a=8,\n",
        "            n_steps=3,\n",
        "            gamma=1.5,\n",
        "            n_independent=2,\n",
        "            n_shared=2,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        self.models['tabnet'].fit(\n",
        "            X_processed.values, y_encoded,\n",
        "            eval_metric=['accuracy'],\n",
        "            patience=3,\n",
        "            max_epochs=5\n",
        "        )\n",
        "\n",
        "        # Store feature importance\n",
        "        self.feature_importance['catboost'] = self.models['catboost'].feature_importances_\n",
        "        self.feature_importance['xgboost'] = self.models['xgboost'].feature_importances_\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Preprocess test data\n",
        "        X_processed = self.preprocess_data(X, train_mode=False)\n",
        "\n",
        "        # Get predictions from each model\n",
        "        pred_catboost = self.models['catboost'].predict_proba(X_processed)\n",
        "        pred_xgboost = self.models['xgboost'].predict_proba(X_processed)\n",
        "        pred_tabnet = self.models['tabnet'].predict_proba(X_processed.values)\n",
        "\n",
        "        # Weighted average of predictions\n",
        "        weighted_pred = (0.4 * pred_catboost +\n",
        "                        0.3 * pred_xgboost +\n",
        "                        0.3 * pred_tabnet)\n",
        "\n",
        "        # Convert to class labels\n",
        "        final_pred = np.argmax(weighted_pred, axis=1)\n",
        "        return self.label_encoder.inverse_transform(final_pred)\n",
        "\n",
        "# Load and prepare your data\n",
        "print(\"Loading data...\")\n",
        "try:\n",
        "    train = pd.read_csv('/content/UNSW_NB15_training-set.csv')\n",
        "    test = pd.read_csv('/content/UNSW_NB15_testing-set.csv')\n",
        "\n",
        "    # Prepare data\n",
        "    X_train = train.drop(['attack_cat'], axis=1)\n",
        "    y_train = train['attack_cat']\n",
        "\n",
        "    if 'attack_cat' in test.columns:\n",
        "        X_test = test.drop(['attack_cat'], axis=1)\n",
        "        y_test = test['attack_cat']\n",
        "    else:\n",
        "        X_test = test\n",
        "        y_test = None\n",
        "\n",
        "    # Train and evaluate model\n",
        "    model = AdvancedEnsembleModel()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\nMaking predictions...\")\n",
        "    if y_test is not None:\n",
        "        y_pred = model.predict(X_test)\n",
        "        results = [\n",
        "            [\"Accuracy\", f\"{accuracy_score(y_test, y_pred):.4f}\"],\n",
        "            [\"Classification Report\", \"\\n\" + classification_report(y_test, y_pred)]\n",
        "        ]\n",
        "        print(\"\\nResults:\")\n",
        "        print(tabulate(results, headers=[\"Metric\", \"Value\"]))\n",
        "    else:\n",
        "        print(\"Predictions:\", model.predict(X_test))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Could not find the dataset files. Please ensure the paths are correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3jl7pHoH_09",
        "outputId": "ece6ed92-edc0-4ccc-f12f-4c36e1d0d1dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Starting advanced model training...\n",
            "Preprocessing data...\n",
            "Training CatBoost...\n",
            "Training XGBoost...\n",
            "Training TabNet...\n",
            "Training completed in 155.08 seconds\n",
            "\n",
            "Making predictions...\n",
            "\n",
            "Results:\n",
            "Metric                 Value\n",
            "---------------------  -------------------------------------------------------\n",
            "Accuracy               0.8595\n",
            "Classification Report  precision    recall  f1-score   support\n",
            "\n",
            "                             Analysis       0.01      0.03      0.01       677\n",
            "                             Backdoor       0.26      0.02      0.03       583\n",
            "                                  DoS       0.86      0.00      0.00      4089\n",
            "                             Exploits       0.64      0.73      0.68     11132\n",
            "                              Fuzzers       0.83      0.76      0.79      6062\n",
            "                              Generic       1.00      0.96      0.98     18871\n",
            "                               Normal       0.91      1.00      0.95     37000\n",
            "                       Reconnaissance       0.90      0.79      0.84      3496\n",
            "                            Shellcode       0.64      0.21      0.32       378\n",
            "                                Worms       0.00      0.00      0.00        44\n",
            "\n",
            "                             accuracy                           0.86     82332\n",
            "                            macro avg       0.60      0.45      0.46     82332\n",
            "                         weighted avg       0.87      0.86      0.84     82332\n"
          ]
        }
      ]
    }
  ]
}